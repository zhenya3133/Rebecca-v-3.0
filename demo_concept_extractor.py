#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å–∏—Å—Ç–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏ —Å–≤—è–∑–µ–π –¥–ª—è Rebecca-Platform.

–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python demo_concept_extractor.py
"""

import asyncio
import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.append(str(Path(__file__).parent / "src"))

from knowledge_graph.concept_extractor import create_concept_extractor

async def demo_basic_extraction():
    """–ë–∞–∑–æ–≤–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –ö–û–ù–¶–ï–ü–¢–û–í")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    extractor = await create_concept_extractor()
    print("‚úÖ –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ —Å–æ–∑–¥–∞–Ω")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
    test_texts = [
        {
            "title": "üî¨ –ù–∞—É—á–Ω–∞—è —Å—Ç–∞—Ç—å—è –æ–± –ò–ò",
            "text": """
            –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É.
            –ö–æ–º–ø–∞–Ω–∏—è Google DeepMind —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∞ —Å–∏—Å—Ç–µ–º—É AlphaFold –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ–ª–∫–æ–≤.
            –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–∑ MIT –∏—Å–ø–æ–ª—å–∑—É—é—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –ª–µ—á–µ–Ω–∏—è —Ä–∞–∫–∞.
            """
        },
        {
            "title": "üì∞ –ù–æ–≤–æ—Å—Ç—å –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
            "text": """
            Tesla –ø–æ–¥ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –ò–ª–æ–Ω–∞ –ú–∞—Å–∫–∞ –∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª–∞ –Ω–æ–≤—ã–π –∞–≤—Ç–æ–ø–∏–ª–æ—Ç.
            –ö–æ–º–ø–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –≤ 2024 –≥–æ–¥—É –Ω–∞ –∑–∞–≤–æ–¥–µ –≤ –ë–µ—Ä–ª–∏–Ω–µ.
            –ê–∫—Ü–∏–∏ Tesla –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 15% –ø–æ—Å–ª–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è.
            """
        },
        {
            "title": "üíº –ë–∏–∑–Ω–µ—Å-–æ—Ç—á–µ—Ç",
            "text": """
            Microsoft —Å–æ–æ–±—â–∏–ª–∞ –æ —Ä–æ—Å—Ç–µ –≤—ã—Ä—É—á–∫–∏ –Ω–∞ 20% –≤ Q3 2024.
            –û–±–ª–∞—á–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã Azure –ø—Ä–∏–Ω–µ—Å–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ 32 –º–∏–ª–ª–∏–∞—Ä–¥–∞ –¥–æ–ª–ª–∞—Ä–æ–≤.
            –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –°–∞—Ç—å—è –ù–∞–¥–µ–ª–ª–∞ –Ω–∞–∑–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–¥–∞—é—â–∏–º–∏—Å—è.
            """
        }
    ]
    
    for i, test_data in enumerate(test_texts, 1):
        print(f"\nüìÑ –¢–µ–∫—Å—Ç {i}: {test_data['title']}")
        print("-" * 40)
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ü–µ–ø—Ç—ã
            result = await extractor.extract_from_text(
                test_data['text'],
                document_type="demo"
            )
            
            print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.processing_time:.2f}s")
            print(f"üéØ –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {len(result.concepts)}")
            print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π: {len(result.relationships)}")
            
            if result.concepts:
                print("\nüèÜ –¢–æ–ø –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏:")
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                sorted_concepts = sorted(
                    result.concepts, 
                    key=lambda x: x.importance_score, 
                    reverse=True
                )
                
                for j, concept in enumerate(sorted_concepts[:5], 1):
                    print(f"  {j}. {concept.text} ({concept.label}) "
                          f"- –≤–∞–∂–Ω–æ—Å—Ç—å: {concept.importance_score:.2f} "
                          f"- —á–∞—Å—Ç–æ—Ç–∞: {concept.frequency}")
            
            if result.relationships:
                print("\nüîó –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏:")
                for rel in result.relationships[:3]:
                    print(f"  ‚Ä¢ {rel.relationship_type} "
                          f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {rel.confidence:.2f})")
            
            print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã
    stats = extractor.get_statistics()
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 30)
    print(f"–í—Å–µ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {stats['total_concepts_extracted']}")
    print(f"–í—Å–µ–≥–æ —Å–≤—è–∑–µ–π –∏–∑–≤–ª–µ—á–µ–Ω–æ: {stats['total_relationships_extracted']}")
    print(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['documents_processed']}")
    if stats.get('average_processing_time'):
        print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats['average_processing_time']:.2f}s")
    
    print("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

async def demo_advanced_features():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π."""
    print("\n\nüöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ü–†–û–î–í–ò–ù–£–¢–´–• –í–û–ó–ú–û–ñ–ù–û–°–¢–ï–ô")
    print("=" * 60)
    
    extractor = await create_concept_extractor()
    
    # –°–ª–æ–∂–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏—è
    complex_text = """
    –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –º–µ–Ω—è–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É. 
    AI —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–∏–µ —Å–Ω–∏–º–∫–∏ –ª—É—á—à–µ –≤—Ä–∞—á–µ–π.
    –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–∞.
    –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –æ–Ω–∫–æ–ª–æ–≥–∏–∏ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –≤—ã—è–≤–ª–µ–Ω–∏—è —Ä–∞–∫–∞.
    Microsoft, Google –∏ IBM –∏–Ω–≤–µ—Å—Ç–∏—Ä—É—é—Ç –º–∏–ª–ª–∏–∞—Ä–¥—ã –≤ AI —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏.
    """
    
    print("üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–æ–∂–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º...")
    
    try:
        result = await extractor.extract_from_text(
            complex_text,
            text_id="complex_demo",
            document_type="advanced_demo"
        )
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        grouped_concepts = 0
        for concept in result.concepts:
            if concept.metadata.get('semantic_group', {}).get('is_grouped'):
                grouped_concepts += 1
        
        if grouped_concepts > 0:
            print(f"üîó –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {grouped_concepts}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã
            for concept in result.concepts:
                group_info = concept.metadata.get('semantic_group', {})
                if group_info.get('is_grouped'):
                    print(f"  ‚Ä¢ –ì—Ä—É–ø–ø–∞ '{concept.text}': {group_info['group_size']} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π
        entity_types = {}
        for concept in result.concepts:
            label = concept.label
            entity_types[label] = entity_types.get(label, 0) + 1
        
        print("\nüìà –¢–∏–ø—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π:")
        for entity_type, count in sorted(entity_types.items()):
            print(f"  ‚Ä¢ {entity_type}: {count}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

async def demo_error_handling():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫."""
    print("\n\nüõ°Ô∏è –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò –û–®–ò–ë–û–ö")
    print("=" * 50)
    
    extractor = await create_concept_extractor()
    
    test_cases = [
        ("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç", ""),
        ("–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç", "–¢–µ—Å—Ç"),
        ("–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã", "!@#$%^&*()"),
        ("–¢–æ–ª—å–∫–æ —á–∏—Å–ª–∞", "123 456 789"),
        ("–û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", "–°–ª–æ–≤–æ " * 1000)
    ]
    
    for name, text in test_cases:
        print(f"\nüîç –¢–µ—Å—Ç: {name}")
        try:
            result = await extractor.extract_from_text(text)
            print(f"  ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
            if result.processing_time > 0:
                print(f"  ‚è±Ô∏è –í—Ä–µ–º—è: {result.processing_time:.3f}s")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    print("ü§ñ –°–ò–°–¢–ï–ú–ê –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –ö–û–ù–¶–ï–ü–¢–û–í –ò –°–í–Ø–ó–ï–ô")
    print("üìÖ Rebecca-Platform - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")
    print("=" * 60)
    
    try:
        await demo_basic_extraction()
        await demo_advanced_features()
        await demo_error_handling()
        
        print("\n\nüéØ –í–°–ï –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò –ó–ê–í–ï–†–®–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("üìö –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: /workspace/reports/concept_extraction_implementation.md")
        
    except Exception as e:
        print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    success = asyncio.run(main())
    sys.exit(0 if success else 1)