"""
–¢–µ—Å—Ç—ã –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏ —Å–≤—è–∑–µ–π.

–°–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–µ–π—Å—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
- –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
- –ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã
"""

import asyncio
import pytest
from pathlib import Path
from typing import List, Dict, Any

from knowledge_graph.concept_extractor import (
    ConceptExtractor,
    ExtractedKnowledge,
    create_concept_extractor
)
from memory_manager.memory_manager import MemoryManager


class TestDocumentTypes:
    """–¢–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
    
    @staticmethod
    def get_scientific_article() -> str:
        """–ü—Ä–∏–º–µ—Ä –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–∏."""
        return """
        –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω–µ: —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã
        
        –í –¥–∞–Ω–Ω–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –º—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è 
        –≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –æ–Ω–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π. –ê–ª–≥–æ—Ä–∏—Ç–º—ã –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è 
        –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
        
        –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è 
        –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞, –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏, –æ–Ω–∫–æ–ª–æ–≥–∏—è.
        
        –ú–µ—Ç–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤–∫–ª—é—á–∞–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π 
        –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ö–¢-—Å–∫–∞–Ω–æ–≤. –¢–æ—á–Ω–æ—Å—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 94.5%, —á—Ç–æ 
        –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –Ω–∞ 15%.
        
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏–º–µ—é—Ç –≤–∞–∂–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è —Å–∏—Å—Ç–µ–º—ã 
        –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–Ω–µ–¥—Ä–µ–Ω—ã –≤ –∫–ª–∏–Ω–∏—á–µ—Å–∫—É—é –ø—Ä–∞–∫—Ç–∏–∫—É –≤ 
        —Ç–µ—á–µ–Ω–∏–µ –±–ª–∏–∂–∞–π—à–∏—Ö –¥–≤—É—Ö –ª–µ—Ç.
        """
    
    @staticmethod
    def get_news_article() -> str:
        """–ü—Ä–∏–º–µ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏."""
        return """
        –ù–æ–≤–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –æ—Ç Tesla –∏–∑–º–µ–Ω–∏—Ç —Ä—ã–Ω–æ–∫ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π
        
        –ö–æ–º–ø–∞–Ω–∏—è Tesla –æ–±—ä—è–≤–∏–ª–∞ –æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–π –±–∞—Ç–∞—Ä–µ–∏ —Å –∑–∞–ø–∞—Å–æ–º 
        —Ö–æ–¥–∞ 1000 –∫–∏–ª–æ–º–µ—Ç—Ä–æ–≤. –ò–ª–æ–Ω –ú–∞—Å–∫, –≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä Tesla, –∑–∞—è–≤–∏–ª, 
        —á—Ç–æ –Ω–æ–≤–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –º–æ–¥–µ–ª—è—Ö 2024 –≥–æ–¥–∞.
        
        –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ Bloomberg —Å—á–∏—Ç–∞—é—Ç, —á—Ç–æ —ç—Ç–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ 
        –∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—É—é —Å—Ä–µ–¥—É –≤ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏. –ê–∫—Ü–∏–∏ Tesla 
        –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 12% –ø–æ—Å–ª–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è.
        
        –≠–∫—Å–ø–µ—Ä—Ç—ã –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π –æ—Ç—Ä–∞—Å–ª–∏ –æ—Ç–º–µ—á–∞—é—Ç, —á—Ç–æ –¥–∞–Ω–Ω–∞—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è 
        —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –¥–ª—è –≤—Å–µ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π.
        """
    
    @staticmethod
    def get_technical_document() -> str:
        """–ü—Ä–∏–º–µ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        return """
        –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        
        –°–∏—Å—Ç–µ–º–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: API Gateway, Service Registry, 
        Load Balancer –∏ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö PostgreSQL. –ö–∞–∂–¥—ã–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å –∏–º–µ–µ—Ç —Å–≤–æ—é 
        –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö MongoDB –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –≤–∫–ª—é—á–∞–µ—Ç: Python, FastAPI, Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è, 
        Docker –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏–∏, Kubernetes –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏, –∏ Prometheus 
        –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–∏—Å—Ç–µ–º—ã.
        
        –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã—Å–æ–∫—É—é 
        –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–∞. –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ 10000 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É 
        —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π –º–µ–Ω–µ–µ 100 –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥.
        """
    
    @staticmethod
    def get_financial_report() -> str:
        """–ü—Ä–∏–º–µ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""
        return """
        –ö–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ Microsoft –∑–∞ Q3 2024
        
        –í—ã—Ä—É—á–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ $52.3 –º–ª—Ä–¥, —á—Ç–æ –Ω–∞ 15% –±–æ–ª—å—à–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é 
        —Å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞. –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ 
        $22.1 –º–ª—Ä–¥.
        
        –û—Å–Ω–æ–≤–Ω–æ–π –≤–∫–ª–∞–¥ –≤ —Ä–æ—Å—Ç –≤—ã—Ä—É—á–∫–∏ –≤–Ω–µ—Å–ª–∏ –æ–±–ª–∞—á–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã Azure –∏ 
        –ø–æ–¥–ø–∏—Å–∫–∏ Office 365. –ü—Ä–æ–¥–∞–∂–∏ –∏–≥—Ä–æ–≤—ã—Ö –∫–æ–Ω—Å–æ–ª–µ–π Xbox –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 8%.
        
        –ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ R&D —Å–æ—Å—Ç–∞–≤–∏–ª–∏ $7.2 –º–ª—Ä–¥. –ö–æ–º–ø–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä—É–µ—Ç 
        —É–≤–µ–ª–∏—á–∏—Ç—å —à—Ç–∞—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –Ω–∞ 12% –≤ —Å–ª–µ–¥—É—é—â–µ–º –∫–≤–∞—Ä—Ç–∞–ª–µ.
        
        –ê–∫—Ü–∏–∏ Microsoft —Ç–æ—Ä–≥—É—é—Ç—Å—è –Ω–∞ –±–∏—Ä–∂–µ NASDAQ –ø–æ–¥ —Ç–∏–∫–µ—Ä–æ–º MSFT.
        """
    
    @staticmethod
    def get_legal_document() -> str:
        """–ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        return """
        –î–æ–≥–æ–≤–æ—Ä –∫—É–ø–ª–∏-–ø—Ä–æ–¥–∞–∂–∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
        
        –ù–∞—Å—Ç–æ—è—â–∏–π –¥–æ–≥–æ–≤–æ—Ä –∑–∞–∫–ª—é—á–µ–Ω –º–µ–∂–¥—É –ø—Ä–æ–¥–∞–≤—Ü–æ–º –û–û–û "–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –ü–ª—é—Å" 
        –∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–º –ò–≤–∞–Ω–æ–≤—ã–º –ò–≤–∞–Ω–æ–º –ò–≤–∞–Ω–æ–≤–∏—á–µ–º.
        
        –ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞: –∫–≤–∞—Ä—Ç–∏—Ä–∞ –ø–ª–æ—â–∞–¥—å—é 78.5 –∫–≤.–º., —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–∞—è –ø–æ 
        –∞–¥—Ä–µ—Å—É –≥. –ú–æ—Å–∫–≤–∞, —É–ª. –¢–≤–µ—Ä—Å–∫–∞—è, –¥. 15, –∫–≤. 42.
        
        –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–±—ä–µ–∫—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 12 500 000 —Ä—É–±–ª–µ–π. –û–ø–ª–∞—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è 
        –µ–¥–∏–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤ —Ç–µ—á–µ–Ω–∏–µ 5 –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –¥–Ω–µ–π –ø–æ—Å–ª–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π 
        —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞ –ø—Ä–∞–≤–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏.
        
        –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å —Å—Ç–æ—Ä–æ–Ω —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç—Å—è –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º 
        –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.
        """


class TestConceptExtractor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
    
    @pytest.fixture
    async def extractor(self):
        """–§–∏–∫—Å—Ç—É—Ä–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
        return await create_concept_extractor()
    
    @pytest.fixture
    async def extractor_with_memory(self):
        """–§–∏–∫—Å—Ç—É—Ä–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ —Å MemoryManager."""
        memory_manager = MemoryManager()
        await memory_manager.start()
        extractor = await create_concept_extractor(memory_manager)
        yield extractor
        await memory_manager.stop()
    
    @pytest.mark.asyncio
    async def test_scientific_article_extraction(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑ –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–∏."""
        text = TestDocumentTypes.get_scientific_article()
        
        result = await extractor.extract_from_text(
            text, 
            document_type="scientific_article"
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        assert result.text_id is not None
        assert result.processing_time > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
        concept_texts = [c.text.lower() for c in result.concepts]
        
        expected_concepts = [
            "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
            "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", 
            "–º–µ–¥–∏—Ü–∏–Ω–∞",
            "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
            "–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏"
        ]
        
        found_concepts = 0
        for expected in expected_concepts:
            if any(expected in text.lower() for text in concept_texts):
                found_concepts += 1
        
        # –û–∂–∏–¥–∞–µ–º –Ω–∞–π—Ç–∏ –Ω–µ –º–µ–Ω–µ–µ 70% –æ–∂–∏–¥–∞–µ–º—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤
        assert found_concepts >= len(expected_concepts) * 0.7
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        importance_scores = [c.importance_score for c in result.concepts]
        assert len(set(importance_scores)) >= 1  # –ï—Å—Ç—å –≤–∞—Ä–∏–∞—Ü–∏—è –≤ –æ—Ü–µ–Ω–∫–∞—Ö
        
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–µ")
    
    @pytest.mark.asyncio
    async def test_news_article_extraction(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏."""
        text = TestDocumentTypes.get_news_article()
        
        result = await extractor.extract_from_text(
            text, 
            document_type="news_article"
        )
        
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –∏ –ø–µ—Ä—Å–æ–Ω
        labels = [c.label for c in result.concepts]
        has_org = any(label in ['ORG', 'PERSON'] for label in labels)
        has_person = 'Tesla' in [c.text for c in result.concepts]
        
        assert has_org or has_person, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –ø–µ—Ä—Å–æ–Ω—ã"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–∏
        assert len(result.relationships) >= 0
        
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–µ")
    
    @pytest.mark.asyncio
    async def test_technical_document_extraction(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        text = TestDocumentTypes.get_technical_document()
        
        result = await extractor.extract_from_text(
            text, 
            document_type="technical_document"
        )
        
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        concept_texts = [c.text.lower() for c in result.concepts]
        
        technical_terms = [
            "–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å",
            "api",
            "docker",
            "kubernetes", 
            "postgresql",
            "mongodb"
        ]
        
        found_technical_terms = []
        for term in technical_terms:
            if any(term in text.lower() for text in concept_texts):
                found_technical_terms.append(term)
        
        # –û–∂–∏–¥–∞–µ–º –Ω–∞–π—Ç–∏ —Ö–æ—Ç—è –±—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        assert len(found_technical_terms) >= len(technical_terms) * 0.5
        
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ")
    
    @pytest.mark.asyncio
    async def test_financial_report_extraction(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""
        text = TestDocumentTypes.get_financial_report()
        
        result = await extractor.extract_from_text(
            text, 
            document_type="financial_report"
        )
        
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        concept_texts = [c.text for c in result.concepts]
        
        # –ò—â–µ–º Microsoft
        has_microsoft = any("microsoft" in text.lower() for text in concept_texts)
        assert has_microsoft or len([c for c in result.concepts if c.label in ['ORG', 'PERSON']]) > 0
        
        # –ò—â–µ–º –¥–µ–Ω–µ–∂–Ω—ã–µ —Å—É–º–º—ã
        has_money = any(c.label == 'MONEY' for c in result.concepts)
        
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º –æ—Ç—á–µ—Ç–µ")
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.relationships)} —Å–≤—è–∑–µ–π")
    
    @pytest.mark.asyncio
    async def test_legal_document_extraction(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑ –ø—Ä–∞–≤–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        text = TestDocumentTypes.get_legal_document()
        
        result = await extractor.extract_from_text(
            text, 
            document_type="legal_document"
        )
        
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–µ—Ä—Å–æ–Ω –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        labels = [c.label for c in result.concepts]
        has_entities = any(label in ['PERSON', 'ORG', 'GPE'] for label in labels)
        
        assert has_entities, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä—Å–æ–Ω—ã, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏"
        
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –≤ –ø—Ä–∞–≤–æ–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ")
    
    @pytest.mark.asyncio
    async def test_batch_extraction(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
        test_documents = [
            TestDocumentTypes.get_scientific_article(),
            TestDocumentTypes.get_news_article(),
            TestDocumentTypes.get_technical_document()
        ]
        
        results = []
        for i, text in enumerate(test_documents):
            result = await extractor.extract_from_text(
                text, 
                document_type=f"test_document_{i}"
            )
            results.append(result)
        
        assert len(results) == 3
        assert all(isinstance(r, ExtractedKnowledge) for r in results)
        assert all(len(r.concepts) > 0 for r in results)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = extractor.get_statistics()
        assert stats['documents_processed'] >= 3
        
        print(f"‚úì –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    
    @pytest.mark.asyncio
    async def test_memory_integration(self, extractor_with_memory: ConceptExtractor):
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å MemoryManager."""
        text = TestDocumentTypes.get_scientific_article()
        
        result = await extractor_with_memory.extract_from_text(
            text,
            document_type="test_memory_integration"
        )
        
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å –≤ –ø–∞–º—è—Ç—å
        # (—ç—Ç–æ –±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —Ç–∞–∫ –∫–∞–∫ –¥–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ MemoryManager)
        
        print("‚úì –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MemoryManager —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    @pytest.mark.asyncio
    async def test_concept_grouping(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
        text = """
        Microsoft —Ä–∞–∑–≤–∏–≤–∞–µ—Ç –æ–±–ª–∞—á–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ Azure. 
        –ö–æ–º–ø–∞–Ω–∏—è Microsoft —Ç–∞–∫–∂–µ –∏–Ω–≤–µ—Å—Ç–∏—Ä—É–µ—Ç –≤ –ò–ò –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ.
        Azure —è–≤–ª—è–µ—Ç—Å—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–º Amazon Web Services.
        """
        
        result = await extractor.extract_from_text(text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ü–µ–ø—Ç "Microsoft" –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑
        microsoft_concepts = [c for c in result.concepts if "microsoft" in c.text.lower()]
        assert len(microsoft_concepts) >= 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        for concept in result.concepts:
            if concept.metadata.get('semantic_group', {}).get('is_grouped'):
                group_size = concept.metadata['semantic_group']['group_size']
                assert group_size >= 2
        
        print(f"‚úì –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
    
    @pytest.mark.asyncio
    async def test_error_handling(self, extractor: ConceptExtractor):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫."""
        # –¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º
        result = await extractor.extract_from_text("")
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) == 0
        
        # –¢–µ—Å—Ç —Å –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º
        result = await extractor.extract_from_text("–¢–µ—Å—Ç")
        assert isinstance(result, ExtractedKnowledge)
        
        print("‚úì –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


class PerformanceTests:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
    
    @pytest.mark.asyncio
    async def test_processing_speed(self):
        """–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        extractor = await create_concept_extractor()
        
        # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        text = TestDocumentTypes.get_scientific_article() * 3  # –£—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        
        import time
        start_time = time.time()
        
        result = await extractor.extract_from_text(text)
        
        processing_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ –∑–∞–Ω–∏–º–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        # (–ø–æ—Ä–æ–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        assert processing_time < 30.0  # –ú–∞–∫—Å–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥
        
        print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")
    
    @pytest.mark.asyncio
    async def test_large_document_processing(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        extractor = await create_concept_extractor()
        
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç
        base_text = TestDocumentTypes.get_technical_document()
        large_text = " ".join([base_text] * 100)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤ 100 —Ä–∞–∑
        
        result = await extractor.extract_from_text(large_text, document_type="large_document")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –±–æ–ª—å—à–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        assert isinstance(result, ExtractedKnowledge)
        assert len(result.concepts) > 0
        assert result.processing_time > 0
        
        print(f"‚úì –ë–æ–ª—å—à–æ–π –¥–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(result.concepts)} –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∑–∞ {result.processing_time:.2f}s")


# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤

async def run_all_tests():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤."""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤...\n")
    
    test_instance = TestConceptExtractor()
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    extractor = await create_concept_extractor()
    
    test_results = []
    
    # –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    tests = [
        ("–ù–∞—É—á–Ω–∞—è —Å—Ç–∞—Ç—å—è", test_instance.test_scientific_article_extraction),
        ("–ù–æ–≤–æ—Å—Ç–Ω–∞—è —Å—Ç–∞—Ç—å—è", test_instance.test_news_article_extraction), 
        ("–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç", test_instance.test_technical_document_extraction),
        ("–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á–µ—Ç", test_instance.test_financial_report_extraction),
        ("–ü—Ä–∞–≤–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç", test_instance.test_legal_document_extraction),
        ("–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", test_instance.test_batch_extraction),
        ("–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ", test_instance.test_concept_grouping),
        ("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫", test_instance.test_error_handling)
    ]
    
    for test_name, test_func in tests:
        try:
            print(f"üîÑ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ç–µ—Å—Ç: {test_name}")
            await test_func(extractor)
            test_results.append((test_name, "‚úÖ PASSED", None))
            print(f"‚úÖ –¢–µ—Å—Ç '{test_name}' –ø—Ä–æ–π–¥–µ–Ω\n")
        except Exception as e:
            test_results.append((test_name, "‚ùå FAILED", str(e)))
            print(f"‚ùå –¢–µ—Å—Ç '{test_name}' –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}\n")
    
    # –¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    perf_tests = PerformanceTests()
    try:
        print("üîÑ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ç–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        await perf_tests.test_processing_speed()
        test_results.append(("–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏", "‚úÖ PASSED", None))
        print("‚úÖ –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–π–¥–µ–Ω\n")
    except Exception as e:
        test_results.append(("–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏", "‚ùå FAILED", str(e)))
        print(f"‚ùå –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}\n")
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("üìä –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 50)
    
    passed = sum(1 for _, status, _ in test_results if "PASSED" in status)
    failed = sum(1 for _, status, _ in test_results if "FAILED" in status)
    
    for test_name, status, error in test_results:
        status_line = f"{test_name}: {status}"
        if error:
            status_line += f" ({error})"
        print(status_line)
    
    print(f"\nüéØ –ò—Ç–æ–≥–æ: {passed} –ø—Ä–æ–π–¥–µ–Ω–æ, {failed} –ø—Ä–æ–≤–∞–ª–µ–Ω–æ")
    
    if failed == 0:
        print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    else:
        print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è")
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
    stats = extractor.get_statistics()
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –≠–ö–°–¢–†–ê–ö–¢–û–†–ê:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {stats['total_concepts_extracted']}")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Å–≤—è–∑–µ–π –∏–∑–≤–ª–µ—á–µ–Ω–æ: {stats['total_relationships_extracted']}")
    print(f"   ‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['documents_processed']}")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats.get('average_processing_time', 0):.2f}s")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–∏ –ø—Ä—è–º–æ–º –≤—ã–∑–æ–≤–µ
    asyncio.run(run_all_tests())